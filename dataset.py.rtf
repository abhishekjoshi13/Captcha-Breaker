{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 import os\
import numpy as np\
import tensorflow as tf\
from PIL import Image\
import string\
\
class CaptchaDataset:\
    def __init__(self, data_dir, img_height=50, img_width=200):\
        self.data_dir = data_dir\
        self.img_height = img_height\
        self.img_width = img_width\
        self.characters = string.ascii_uppercase + string.digits\
        self.sequence_length = 5\
        self.char_to_idx = \{char: idx for idx, char in enumerate(self.characters)\}\
        self.idx_to_char = \{idx: char for idx, char in enumerate(self.characters)\}\
        self.images = []\
        self.labels = []\
        \
    def load_dataset(self):\
        if not os.path.exists(self.data_dir):\
            print(f"Directory \{self.data_dir\} does not exist. No data to load.")\
            return\
        \
        image_files = [f for f in os.listdir(self.data_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\
        \
        if not image_files:\
            print(f"No images found in \{self.data_dir\}")\
            return\
            \
        for img_file in image_files:\
            img_path = os.path.join(self.data_dir, img_file)\
            label = os.path.splitext(img_file)[0]\
            \
            if len(label) != self.sequence_length:\
                continue\
                \
            try:\
                image = Image.open(img_path).convert('RGB')\
                image = image.resize((self.img_width, self.img_height))\
                image_array = np.array(image) / 255.0\
                \
                self.images.append(image_array)\
                \
                label_array = []\
                for char in label:\
                    if char in self.char_to_idx:\
                        one_hot = np.zeros(len(self.characters))\
                        one_hot[self.char_to_idx[char]] = 1\
                        label_array.append(one_hot)\
                \
                if len(label_array) == self.sequence_length:\
                    self.labels.append(label_array)\
                    \
            except Exception as e:\
                print(f"Error processing \{img_file\}: \{e\}")\
        \
        if self.images:\
            self.images = np.array(self.images)\
            self.labels = np.array(self.labels)\
            print(f"Loaded \{len(self.images)\} images for training")\
        else:\
            print("No valid images found for training")\
        \
    def split_data(self, test_size=0.2):\
        if len(self.images) == 0:\
            return None, None\
            \
        dataset = tf.data.Dataset.from_tensor_slices((self.images, self.labels))\
        dataset = dataset.shuffle(buffer_size=len(self.images))\
        \
        train_size = int((1 - test_size) * len(self.images))\
        train_dataset = dataset.take(train_size).batch(16).prefetch(tf.data.AUTOTUNE)\
        val_dataset = dataset.skip(train_size).batch(16).prefetch(tf.data.AUTOTUNE)\
        \
        return train_dataset, val_dataset}